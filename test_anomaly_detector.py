#!/usr/bin/env python3
"""
Standalone anomaly detector for testing without Docker.
This version reads from the local logs directory.
"""

import pandas as pd
from adtk.data import validate_series
from adtk.detector import OutlierDetector
from sklearn.neighbors import LocalOutlierFactor
import time
import os
import numpy as np

# Path to the log file generated by the standalone physical process simulator
LOG_FILE = "./logs/power_flow.log"

def monitor_and_detect_standalone():
    """
    Monitors the power flow log file and detects anomalies (standalone version).
    """
    print("--- Standalone Anomaly Detection Agent Started ---")
    print(f"Waiting for log file at: {LOG_FILE}")

    # Ensure the log directory exists
    os.makedirs(os.path.dirname(LOG_FILE), exist_ok=True)

    # Wait for log file to be created
    while not os.path.exists(LOG_FILE):
        print("Waiting for log file to be created...")
        time.sleep(2)

    print("✅ Log file found. Starting monitoring...")
    last_size = 0

    while True:
        try:
            # Check if file has grown
            current_size = os.path.getsize(LOG_FILE)
            if current_size <= last_size:
                print(f"⏳ Waiting for new data... (file size: {current_size} bytes)")
                time.sleep(5)
                continue
            
            last_size = current_size
            
            # Read the latest data from the log file
            try:
                data = pd.read_csv(
                    LOG_FILE,
                    index_col="timestamp",
                    parse_dates=True,
                    names=["timestamp", "loading_percent"]
                )
                
                if len(data) < 5:  # Need at least 5 data points
                    print(f"📊 Need more data points (have {len(data)}, need at least 5)")
                    time.sleep(5)
                    continue
                
                print(f"📊 Analyzing {len(data)} data points...")
                print(f"   Loading range: {data['loading_percent'].min():.1f}% - {data['loading_percent'].max():.1f}%")
                print(f"   Mean loading: {data['loading_percent'].mean():.1f}%")
                
            except Exception as e:
                print(f"❌ Error reading CSV: {e}")
                time.sleep(5)
                continue

            # Filter out NaN values
            data = data.dropna()
            
            if len(data) < 5:
                print(f"⚠️  After filtering NaN values, only {len(data)} data points remain")
                time.sleep(5)
                continue

            # Simple anomaly detection using statistical methods
            try:
                loading_series = data['loading_percent']
                
                # Calculate statistics
                mean_loading = loading_series.mean()
                std_loading = loading_series.std()
                
                # Define anomalies as values beyond 2.5 standard deviations
                threshold = 2.5
                lower_bound = mean_loading - threshold * std_loading
                upper_bound = mean_loading + threshold * std_loading
                
                # Find anomalies
                anomaly_mask = (loading_series < lower_bound) | (loading_series > upper_bound)
                anomalies = loading_series[anomaly_mask]
                
                if len(anomalies) > 0:
                    print(f"\n🚨 --- ANOMALY DETECTED! ---")
                    print(f"   Found {len(anomalies)} anomalous data points:")
                    print(f"   Normal range: {lower_bound:.1f}% - {upper_bound:.1f}%")
                    
                    # Show last 5 anomalies
                    for timestamp, value in anomalies.tail(5).items():
                        status = 'HIGH' if value > upper_bound else 'LOW'
                        print(f"   {timestamp}: {value:.2f}% loading ({status})")
                    
                    print("   This could indicate:")
                    latest_anomaly = anomalies.iloc[-1]
                    if latest_anomaly > upper_bound:
                        print("   - Equipment overload")
                    else:
                        print("   - Equipment underload")
                    print("   - System instability")
                    print("   - Measurement errors")
                    print("   - Cyber attack")
                else:
                    latest_loading = loading_series.iloc[-1]
                    print(f"✅ ({pd.Timestamp.now().strftime('%H:%M:%S')}) System normal")
                    print(f"   Latest: {latest_loading:.1f}% loading (range: {lower_bound:.1f}% - {upper_bound:.1f}%)")

            except Exception as e:
                print(f"❌ Error in anomaly detection: {e}")
                print("   This might be due to insufficient data variation")

        except KeyboardInterrupt:
            print("\n🛑 Anomaly detection stopped by user")
            break
        except Exception as e:
            print(f"❌ General error: {e}")

        time.sleep(10)  # Check for anomalies every 10 seconds

def test_with_synthetic_data():
    """Create synthetic data with anomalies for testing"""
    print("🧪 Creating synthetic test data with anomalies...")
    
    # Ensure log directory exists
    os.makedirs(os.path.dirname(LOG_FILE), exist_ok=True)
    
    # Generate synthetic data
    timestamps = pd.date_range(start='2024-01-01', periods=100, freq='5s')
    
    # Normal loading pattern (20-80%)
    normal_loading = 50 + 15 * np.sin(np.linspace(0, 4*np.pi, 100)) + np.random.normal(0, 3, 100)
    
    # Add some anomalies
    normal_loading[30:35] = 150  # High anomaly
    normal_loading[60:62] = 5    # Low anomaly
    
    # Write to file
    with open(LOG_FILE, 'w') as f:
        for timestamp, loading in zip(timestamps, normal_loading):
            f.write(f"{timestamp.isoformat()},{loading:.2f}\n")
    
    print(f"✅ Synthetic data created with {len(timestamps)} points")
    print("   Anomalies added at indices 30-35 (high) and 60-62 (low)")
    
    # Run anomaly detection once
    monitor_and_detect_standalone()

if __name__ == "__main__":
    import sys
    
    if len(sys.argv) > 1 and sys.argv[1] == "--test":
        test_with_synthetic_data()
    else:
        monitor_and_detect_standalone()
